{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 0.13315506279468536, Validation Loss = 0.1283332109451294\n",
      "Epoch 1, Iteration 0: Training Loss = 0.06646596640348434, Validation Loss = 0.06703242659568787\n",
      "Epoch 2, Iteration 0: Training Loss = 0.06839437782764435, Validation Loss = 0.07066626101732254\n",
      "Epoch 3, Iteration 0: Training Loss = 0.06882544606924057, Validation Loss = 0.06635159254074097\n",
      "Epoch 4, Iteration 0: Training Loss = 0.0693722814321518, Validation Loss = 0.07025878876447678\n",
      "Epoch 5, Iteration 0: Training Loss = 0.06921987980604172, Validation Loss = 0.0727827399969101\n",
      "Epoch 6, Iteration 0: Training Loss = 0.06652132421731949, Validation Loss = 0.06517942994832993\n",
      "Epoch 7, Iteration 0: Training Loss = 0.06958481669425964, Validation Loss = 0.06941505521535873\n",
      "Epoch 8, Iteration 0: Training Loss = 0.07180159538984299, Validation Loss = 0.06795158237218857\n",
      "Epoch 9, Iteration 0: Training Loss = 0.06893263757228851, Validation Loss = 0.07117502391338348\n",
      "Epoch 00010: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "# combining a transformer with a cellular automata: dna sim\n",
    "from dna_ca import DNA_CA\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 128\n",
    "max_iter = 5000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 64\n",
    "n_head = 16\n",
    "n_layer = 32\n",
    "dropout = 0.2\n",
    "grid_width = 3\n",
    "text = []\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['A', 'T', 'C', 'G', '0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])\n",
    "\n",
    "#  train and test splits \n",
    "def generate_random_input_string(size):\n",
    "    \"\"\"Generate a random grid as a string for a given grid size.\"\"\"\n",
    "    game1 = DNA_CA(size, grid_width, step_count)\n",
    "    x = (game1.initialize_grid_with_modifiers())\n",
    "    return (game1.flatten_grid(x))\n",
    "\n",
    "def generate_ATCG_sequence(batch_size, grid_size, step_count):\n",
    "    initial_states = [generate_random_input_string(grid_size) for _ in range(batch_size)]\n",
    "    final_states = []\n",
    "    for state in initial_states:\n",
    "        game = DNA_CA(grid_size, grid_width, step_count)\n",
    "        final_state_array = game.run_simulation()\n",
    "        # final_state_str = ''.join(final_state_array.flatten())\n",
    "        final_states.append(final_state_array)\n",
    "    return initial_states, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size\n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_ATCG_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            # loss = F.cross_entropy(logits, targets)\n",
    "            loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_atcg_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: C00G11T10A00T10T11A01A00G01T01C01C11T11G00T00T10G00A10G00T01C01G00G01T11G10A11A00G11C01T00C10A10G10G01C00G11T00T00A00C01T01C11C01G10A00C10C00C11T10G11G11T10T11C00A00G00A00C11G00C01A01A10C00A00\n",
      "Generated from T is: C00G11T10A00T10T11A01A00G01T01C01C11T11G00T00T10G00A10G00T01C01G00G01T11G10A11A00G11C01T00C10A10G10G01C00G11T00T00A00C01T01C11C01G10A00C10C00C11T10G11G11T10T11C00A00G00A00C11G00C01A01A10C00A00e1GCGCsGe1AAeGT1eG01AACss010sTGCCGC1TTseGC000s0C1eC1CT0A0GsGACseC0T0sATsAsG0100GAsTsT0TsG0CA1TAsCGCG0G1sCGGCTTAeG0CTAGCGTGCss00TsCAseGAsGGTesGATGCGsA000CsAe1eCGesGTT1Cs1s00010GGCCA01111T1s1TTG\n",
      "Generated from CA is: T10G11T10G11G11G01G00G01G00A01G00C00G00T01G00G01A01T00A01G01G01G01A00G00\n",
      "\n",
      "Generated from CA finally is: T10G11T10G11G11G01G00G01G00A01G00C00G00T01G00G01A01T00A01G01G01G01A00G00\n",
      "\n",
      "\n",
      "Generated from T modified is: 1GCGCsGe1AAeGT1eG01AACss010sTGCCGC1TTseGC000s0C1eC1CT0A0GsGACseC0T0sATsAsG0100GAsTsT0TsG0CA1TAsCGCG0G1sCGGCTTAeG0CTAGCGTGCss00TsCAseGAsGGTesGATGCGsA000CsAe1eCGesGTT1Cs1s00010GGCCA01111T1s1TTG\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_atcg_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "generations = 2\n",
    "grid_length = input_length\n",
    "grid_width = 3 # Keep it square - no idea why it has to be\n",
    "game1 = DNA_CA(input_length, input_length, step_count)\n",
    "x = (game1.initialize_grid_with_modifiers())\n",
    "input_sequence = (game1.flatten_grid(x))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = DNA_CA(grid_length, grid_width, generations=generations)\n",
    "print(f\"Generated from T is: {generated_text_t}\")\n",
    "\n",
    "if generated_text_t.startswith('s'):\n",
    "    generated_text_t = generated_text_t[1:]\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "_, model_generated_sequence = generated_text_t.split('e', 1)\n",
    "\n",
    "print(f\"Generated from CA is: {generated_text_ca}\")\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'A': 'red', 'T': 'blue', 'C': 'green', 'G': 'yellow', '0': 'grey', '1': 'white', ' ': 'black'}\n",
    "    colors = []\n",
    "    \n",
    "    if isinstance(grid, np.ndarray):  # Handling NumPy arrays from CA generations\n",
    "        grid = grid.astype(str)  # Ensure the array elements are strings for color mapping\n",
    "        for generation in grid:\n",
    "            for cell in generation.flat:\n",
    "                colors.append(base_colors[cell])\n",
    "    elif isinstance(grid, str):  # Handling model generated sequences as strings\n",
    "        for base in grid:\n",
    "            colors.append(base_colors.get(base, 'black'))  # Default to black for unexpected characters\n",
    "    \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA finally is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T modified is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output\n",
    "\n",
    "# ca = game.unflatten_string(generated_text_ca)\n",
    "# t = game.unflatten_string(model_generated_sequence)\n",
    "# game.visualize_grid_with_modifiers(ca)\n",
    "# game.visualize_grid_with_modifiers(t)  # Use the fixed, split decoded output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
