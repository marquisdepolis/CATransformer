{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 0.1302030086517334, Validation Loss = 0.1554049253463745\n",
      "Epoch 1, Iteration 0: Training Loss = 0.0714820846915245, Validation Loss = 0.0702974796295166\n",
      "Epoch 2, Iteration 0: Training Loss = 0.06485225260257721, Validation Loss = 0.07118583470582962\n",
      "Epoch 3, Iteration 0: Training Loss = 0.07145623862743378, Validation Loss = 0.0663643628358841\n",
      "Epoch 4, Iteration 0: Training Loss = 0.06755555421113968, Validation Loss = 0.06861121207475662\n",
      "Epoch 5, Iteration 0: Training Loss = 0.06968974322080612, Validation Loss = 0.06846154481172562\n",
      "Epoch 6, Iteration 0: Training Loss = 0.06927210092544556, Validation Loss = 0.07020429521799088\n",
      "Epoch 00007: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 7, Iteration 0: Training Loss = 0.07184816896915436, Validation Loss = 0.07020702958106995\n",
      "Epoch 8, Iteration 0: Training Loss = 0.06818435341119766, Validation Loss = 0.0700686052441597\n",
      "Epoch 9, Iteration 0: Training Loss = 0.07083558291196823, Validation Loss = 0.06581835448741913\n"
     ]
    }
   ],
   "source": [
    "# combining a transformer with a cellular automata: dna sim\n",
    "from dna_ca import DNA_CA\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 128\n",
    "max_iter = 2000\n",
    "epochs = 10\n",
    "eval_interval = 200\n",
    "learning_rate = 5e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 64\n",
    "n_head = 16\n",
    "n_layer = 32\n",
    "dropout = 0.2\n",
    "grid_width = 3\n",
    "text = []\n",
    "# torch.manual_seed(100)\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['A', 'T', 'C', 'G', '0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])\n",
    "\n",
    "#  train and test splits \n",
    "def generate_ATCG_sequence(batch_size, grid_size, step_count):\n",
    "    final_states = []\n",
    "    initial_states = []\n",
    "    for _ in range(batch_size):\n",
    "        game = DNA_CA(grid_size, grid_width, step_count)\n",
    "        initial_state_array = game.initialize_grid_with_modifiers()\n",
    "        initial_state_str = game.flatten_grid(initial_state_array)\n",
    "        final_state_array = game.generate_output_with_modifiers(initial_state_array)\n",
    "        initial_states.append(initial_state_str)        \n",
    "        final_state_str = game.flatten_grid(final_state_array)\n",
    "        final_states.append(final_state_str)\n",
    "    return initial_states, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size\n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_ATCG_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            # loss = F.cross_entropy(logits, targets)\n",
    "            loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_atcg_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: T11G11C11G01G11C00T10G10T00G10A11A00C00A01A11T00A11C00A00C10G00A11G01T00G00A00A11A01G10G01G11G11A11C01C11C10T01A01A00A00A00T11C01T00A11A00G01T10G00C00T01T10G10T00A10T01A11A01C00T01T01G10A11C00\n",
      "Generated from T is: T11G11C11G01G11C00T10G10T00G10A11A00C00A01A11T00A11C00A00C10G00A11G01T00G00A00A11A01G10G01G11G11A11C01C11C10T01A01A00A00A00T11C01T00A11A00G01T10G00C00T01T10G10T00A10T01A11A01C00T01T01G10A11C00esTGeGGsGG1eA0C0ee1GGTGTeGGCG1GTTAAGGC0CG0CssCsG0AAsTs0eGTe0A01sAT0GG1es1TCA00ATeAC101GTGG001T1A0AGGAACTseCssee011ATsGs0s1GsGsGTGGCAAe0eTe010GsA0ssTe0010s0GC0C1e1eAGCCC1T0T10111TCTs0eGT1GGssT1\n",
      "\n",
      "Generated from CA finally is: G11G11G11G11G11G11C11G11T11T10A10T10G10T10A10T11A10T10A10T10A10A11A11G11\n",
      "\n",
      "\n",
      "Generated from T modified is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABiIAAADECAYAAAAS7zkeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYS0lEQVR4nO3da4xV5d3w4f8wwjA4MNhxOHh4BEdExVQMlYOFYYQqaK0gCuUQC4KpR0SrNWqtQGs906LUE5ogIoMoFQmmFEFBUEFs1ZhAtFqFthoZjiKMKMJ6Pxj26ziDIOWG5nmuKyFm3/vea91rz/7i/u21Vl6WZVkAAAAAAAAkUO9ALwAAAAAAAPjfS4gAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAADgv9qjjz4aeXl5sXLlyv+6dVRUVERFRcV+X8uB2u/eGjZsWLRq1WqP5xYVFaVdUAJ7+vlYvXp1nH/++VFSUhJ5eXkxfvz4WLhwYeTl5cXChQv365oBAGB/ESIAANivzjnnnGjUqFF8+umnu5wzZMiQaNCgQaxbt24/ruy/y4oVK2LMmDEHPMCkUF1dHWPGjEnyxXtFRUXk5eVFmzZt6nx+3rx5kZeXF3l5eTFjxox9vv/dufrqq2Pu3Llxww03xJQpU6J37977fQ0AALC/HXSgFwAAwP8tQ4YMidmzZ8fMmTPjZz/7Wa3nq6urY9asWdG7d+8oKSmJCy64IAYOHBgFBQUHYLXf7rnnnku27RUrVsTYsWOjoqKi1tkEKfebwsMPPxw7duzIPa6uro6xY8dGRCQ5s6Nhw4bx3nvvxbJly6Jjx441nps6dWo0bNgwtm7dus/3+011/Z1eeOGF6NOnT1x77bW5sWOPPTY+++yzaNCgQfI1AQDAgeCMCAAA9qtzzjknGjduHJWVlXU+P2vWrNiyZUsMGTIkIiLy8/OjYcOGkZeXtz+XuUcaNGhwQL48PlD73Vv169ffryGprKws2rZtG9OmTasxvnXr1pg5c2b8+Mc/3i/rqOvvVFVVFU2bNq0xVq9evWjYsGHUq7dv/vdsy5Yt+2Q7AACwrwgRAADsV4WFhdGvX794/vnno6qqqtbzlZWV0bhx4zjnnHMiou5r7//1r3+NXr16xaGHHhqFhYXRunXrGD58eO75XV1zf+XKlZGXlxePPvpobuytt96KYcOGxdFHHx0NGzaMFi1axPDhw/foslDfvAdAq1atcpf9+ea/nWtZtWpVXHbZZdG2bdsoLCyMkpKS6N+/f43je/TRR6N///4REXHaaafV2kZd9x6oqqqKESNGRPPmzaNhw4Zx0kknxeTJk+s8/rvvvjsmTpwYZWVlUVBQEKecckq89tpr33qsGzdujPz8/Lj33ntzY2vXro169epFSUlJZFmWG7/00kujRYsWucdfv0fEypUro7S0NCIixo4dmzu2MWPG1Njfhx9+GH379o2ioqIoLS2Na6+9NrZv3/6ta/y6QYMGxfTp02uciTF79uyorq6OAQMG1PmaN954I84888xo0qRJFBUVRc+ePWPp0qW15i1fvjx69OgRhYWFccQRR8Qtt9xSYz87ff3vtPNznGVZ3Hfffbnjjtj15/XVV1+N3r17R3FxcTRq1Ci6d+8eL7/8co05Y8aMiby8vFixYkUMHjw4DjnkkOjatWtERHz88cdx4YUXxhFHHBEFBQXRsmXL6NOnz//Ky30BAPDfzaWZAADY74YMGRKTJ0+OJ598Mq644orc+Pr162Pu3LkxaNCgKCwsrPO1VVVVccYZZ0RpaWlcf/310bRp01i5cmU8/fTTe7WWefPmxfvvvx8XXnhhtGjRIpYvXx4TJ06M5cuXx9KlS7/TmRjjx4+PzZs31xj7wx/+EG+++WaUlJRERMRrr70Wr7zySgwcODCOOOKIWLlyZTzwwANRUVERK1asiEaNGkV5eXlceeWVce+998aNN94Yxx9/fERE7r/f9Nlnn0VFRUW89957ccUVV0Tr1q3jqaeeimHDhsXGjRtj1KhRNeZXVlbGp59+GhdffHHk5eXFnXfeGf369Yv3338/6tevX+c+mjZtGieeeGIsWrQorrzyyoiIeOmllyIvLy/Wr18fK1asiHbt2kVExOLFi6Nbt251bqe0tDQeeOCBuPTSS+Pcc8+Nfv36RUTE97///dyc7du3R69evaJTp05x9913x/z582PcuHFRVlYWl1566bf+DXYaPHhw7j4UPXr0yB13z549o1mzZrXmL1++PLp16xZNmjSJ6667LurXrx8PPfRQVFRUxIsvvhidOnWKiK++3D/ttNPiyy+/jOuvvz4OPvjgmDhx4i4/rzuVl5fHlClT4oILLojTTz+9zsuSfd0LL7wQZ555ZnTo0CFGjx4d9erVi0mTJkWPHj1i8eLFtS451b9//2jTpk3ceuutuSh03nnnxfLly2PkyJHRqlWrqKqqinnz5sU///nPPb55OAAA7BMZAADsZ19++WXWsmXLrEuXLjXGH3zwwSwisrlz5+bGJk2alEVE9sEHH2RZlmUzZ87MIiJ77bXXdrn9BQsWZBGRLViwoMb4Bx98kEVENmnSpNxYdXV1rddPmzYti4hs0aJFu1xHlmVZ9+7ds+7du+9yHU8++WQWEdlvfvObb93fkiVLsojIHnvssdzYU089Vecx1LXf8ePHZxGRPf7447mxL774IuvSpUtWVFSUbdq0qcbxl5SUZOvXr8/NnTVrVhYR2ezZs3d5LFmWZZdffnnWvHnz3ONf/OIXWXl5edasWbPsgQceyLIsy9atW5fl5eVl99xzT27e0KFDs6OOOir3eM2aNVlEZKNHj661j6FDh9Z6z7Isy04++eSsQ4cO37q+LPvqvWnXrl2WZVn2gx/8IBsxYkSWZVm2YcOGrEGDBtnkyZNzn4+nnnoq97q+fftmDRo0yP7xj3/kxj766KOscePGWXl5eW7sqquuyiIie/XVV3NjVVVVWXFx8R59PiIiu/zyy2uMffPzumPHjqxNmzZZr169sh07duTmVVdXZ61bt85OP/303Njo0aOziMgGDRpUY5sbNmzIIiK76667dvueAQBAai7NBADAfpefnx8DBw6MJUuW1LhMTGVlZTRv3jx69uy5y9fuvL7+s88+G9u2bfuP1/L1X7Jv3bo11q5dG507d46IiNdff32vt7tixYoYPnx49OnTJ2666aY697dt27ZYt25dHHPMMdG0adO93t+f//znaNGiRQwaNCg3Vr9+/bjyyitj8+bN8eKLL9aY/9Of/jQOOeSQ3OOdZy+8//7737qfbt26xerVq+Odd96JiK/OfCgvL49u3brF4sWLI+KrsySyLNvlGRF76pJLLqm1792t75sGDx4cTz/9dHzxxRcxY8aMyM/Pj3PPPbfWvO3bt8dzzz0Xffv2jaOPPjo33rJlyxg8eHC89NJLsWnTpoj46r3u3LlzjTMSSktLc/c02RfefPPNePfdd2Pw4MGxbt26WLt2baxduza2bNkSPXv2jEWLFtW6FNQ336/CwsJo0KBBLFy4MDZs2LDP1gYAAHtDiAAA4IDY+cXtzptW//vf/47FixfHwIEDIz8/f5ev6969e5x33nkxduzYOPTQQ6NPnz4xadKk+Pzzz/dqHevXr49Ro0ZF8+bNo7CwMEpLS6N169YREfHJJ5/s1TY3bdoU/fr1i8MPPzwee+yxGpd3+uyzz+Lmm2+OI488MgoKCuLQQw+N0tLS2Lhx417vb9WqVdGmTZtaNzveeSmnVatW1Rj/n//5nxqPd0aJ3X1hvTMuLF68OLZs2RJvvPFGdOvWLcrLy3MhYvHixdGkSZM46aST9upYIiIaNmyYu4/E19f4Xb9QHzhwYHzyyScxZ86cmDp1apx99tnRuHHjWvPWrFkT1dXV0bZt21rPHX/88bFjx47417/+FRH//73+prpeu7fefffdiIgYOnRolJaW1vj3yCOPxOeff17rs7LzM7tTQUFB3HHHHTFnzpxo3rx5lJeXx5133hkff/zxPlsnAADsKfeIAADggOjQoUMcd9xxMW3atLjxxhtj2rRpkWXZbn9ZnpeXFzNmzIilS5fG7NmzY+7cuTF8+PAYN25cLF26NIqKinZ5X4e6bnY8YMCAeOWVV+KXv/xltG/fPoqKimLHjh3Ru3fvOm9AvCeGDRsWH330USxbtiyaNGlS47mRI0fGpEmT4qqrroouXbpEcXFx5OXlxcCBA/d6f9/VrkJP9rUbTtflsMMOi9atW8eiRYuiVatWkWVZdOnSJUpLS2PUqFGxatWqWLx4cZx66qm1osi+WN931bJly6ioqIhx48bFyy+/HH/605/2yXZT2/k5uOuuu6J9+/Z1zikqKqrxuK57VFx11VXxk5/8JJ555pmYO3du/PrXv47bbrstXnjhhTj55JP3+boBAGBXhAgAAA6YIUOGxK9//et46623orKyMtq0aROnnHLKHr22c+fO0blz5/jd734XlZWVMWTIkHjiiSfioosuyv3Cf+PGjTVe880zAzZs2BDPP/98jB07Nm6++ebc+M5fpO+N22+/PZ555pl4+umn47jjjqv1/IwZM2Lo0KExbty43NjWrVtrrfW73CT7qKOOirfeeit27NhRIwC8/fbbuef3lW7dusWiRYuidevW0b59+2jcuHGcdNJJUVxcHH/5y1/i9ddfj7Fjx37rNr7Lsf2nBg8eHBdddFE0bdo0zjrrrDrnlJaWRqNGjXKXnPq6t99+O+rVqxdHHnlkRHz1Xtb1+ajrtXurrKwsIiKaNGkSP/rRj/7jbV1zzTVxzTXXxLvvvhvt27ePcePGxeOPP74vlgoAAHvEpZkAADhgdp79cPPNN8ebb765R9fZ37BhQ61f7u/81fjOyzMdddRRkZ+fH4sWLaox7/7776/xeOcv77+5vfHjx+/xMXzd/Pnz46abbopf/epX0bdv3zrn5Ofn19rfhAkTap2tcfDBB0dE7ZhSl7POOis+/vjjmD59em7syy+/jAkTJkRRUVF07979ux3It+jWrVusXLkypk+fnrtUU7169eLUU0+N3//+97Ft27bd3h+iUaNGEbFnx/afOv/882P06NFx//33R4MGDeqck5+fH2eccUbMmjWrxj1LVq9eHZWVldG1a9fcmS1nnXVWLF26NJYtW5abt2bNmpg6deo+W3OHDh2irKws7r777ti8eXOt59esWbPbbVRXV8fWrVtrjJWVlUXjxo33+jJmAACwt5wRAQDAAdO6des49dRTY9asWRERexQiJk+eHPfff3+ce+65UVZWFp9++mk8/PDD0aRJk9wv3ouLi6N///4xYcKEyMvLi7Kysnj22WejqqqqxraaNGmSu3b+tm3b4vDDD4/nnnsuPvjgg706nkGDBkVpaWm0adOm1i/OTz/99GjevHmcffbZMWXKlCguLo4TTjghlixZEvPnz4+SkpIa89u3bx/5+flxxx13xCeffBIFBQXRo0ePaNasWa39/vznP4+HHnoohg0bFn/729+iVatWMWPGjHj55Zdj/Pjxdd4XYW/tjAzvvPNO3Hrrrbnx8vLymDNnThQUFOz2rJbCwsI44YQTYvr06XHsscfG9773vTjxxBPjxBNP3Gfr3Km4uDjGjBmz23m33HJLzJs3L7p27RqXXXZZHHTQQfHQQw/F559/HnfeeWdu3nXXXRdTpkyJ3r17x6hRo+Lggw+OiRMn5s5K2Rfq1asXjzzySJx55pnRrl27uPDCC+Pwww+PDz/8MBYsWBBNmjSJ2bNnf+s2/v73v0fPnj1jwIABccIJJ8RBBx0UM2fOjNWrV8fAgQP3yToBAGBPCREAABxQQ4YMiVdeeSU6duwYxxxzzG7nd+/ePZYtWxZPPPFErF69OoqLi6Njx44xderUGjfsnTBhQmzbti0efPDBKCgoiAEDBsRdd91V68vuysrKGDlyZNx3332RZVmcccYZMWfOnDjssMO+87GsXbs2Ir66yfA3LViwIJo3bx733HNP5Ofnx9SpU2Pr1q3xwx/+MObPnx+9evWqMb9Fixbx4IMPxm233RYjRoyI7du3x4IFC+oMEYWFhbFw4cK4/vrrY/LkybFp06Zo27ZtTJo0KYYNG/adj+PbtG3bNpo1axZVVVXRtWvX3PjOQNGxY8coKCjY7XYeeeSRGDlyZFx99dXxxRdfxOjRo5OEiD3Vrl27WLx4cdxwww1x2223xY4dO6JTp07x+OOPR6dOnXLzWrZsGQsWLIiRI0fG7bffHiUlJXHJJZfEYYcdFiNGjNhn66moqIglS5bEb3/72/jjH/8YmzdvjhYtWkSnTp3i4osv3u3rjzzyyBg0aFA8//zzMWXKlDjooIPiuOOOiyeffDLOO++8fbZOAADYE3nZ7u5IBwAAAAAAsJfcIwIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGSECAAAAAAAIBkhAgAAAAAASEaIAAAAAAAAkhEiAAAAAACAZIQIAAAAAAAgGSECAAAAAABIRogAAAAAAACSESIAAAAAAIBkhAgAAAAAACAZIQIAAAAAAEhGiAAAAAAAAJIRIgAAAAAAgGT+H6lhzRIfa3fTAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_atcg_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "generations = 2\n",
    "grid_length = input_length\n",
    "grid_width = 3\n",
    "game1 = DNA_CA(input_length, input_length, step_count)\n",
    "x = (game1.initialize_grid_with_modifiers())\n",
    "input_sequence = (game1.flatten_grid(x))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = DNA_CA(grid_length, grid_width, generations=generations)\n",
    "print(f\"Generated from T is: {generated_text_t}\")\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "\n",
    "_, model_generated_sequence = generated_text_t[len(input_sequence)].split('e', 1)\n",
    "# if model_generated_sequence.startswith('s'):\n",
    "#     model_generated_sequence = model_generated_sequence[1:]\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'A': 'red', 'T': 'blue', 'C': 'green', 'G': 'yellow', '0': 'grey', '1': 'white'}\n",
    "    colors = []\n",
    "    \n",
    "    if isinstance(grid, np.ndarray):  # Handling NumPy arrays from CA generations\n",
    "        grid = grid.astype(str)  # Ensure the array elements are strings for color mapping\n",
    "        for generation in grid:\n",
    "            for cell in generation.flat:\n",
    "                colors.append(base_colors[cell])\n",
    "    elif isinstance(grid, str):  # Handling model generated sequences as strings\n",
    "        for base in grid:\n",
    "            colors.append(base_colors.get(base, 'black'))  # Default to black for unexpected characters\n",
    "    \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA finally is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T modified is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
