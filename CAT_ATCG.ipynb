{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 0.13227427005767822, Validation Loss = 0.11348866671323776\n",
      "Epoch 1, Iteration 0: Training Loss = 0.06820198893547058, Validation Loss = 0.06665059924125671\n",
      "Epoch 2, Iteration 0: Training Loss = 0.06383374333381653, Validation Loss = 0.06218244880437851\n",
      "Epoch 3, Iteration 0: Training Loss = 0.06924435496330261, Validation Loss = 0.06556499004364014\n",
      "Epoch 4, Iteration 0: Training Loss = 0.06846335530281067, Validation Loss = 0.06765321642160416\n",
      "Epoch 5, Iteration 0: Training Loss = 0.06541860103607178, Validation Loss = 0.06710821390151978\n",
      "Epoch 00006: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 6, Iteration 0: Training Loss = 0.07249315083026886, Validation Loss = 0.06847797334194183\n",
      "Epoch 7, Iteration 0: Training Loss = 0.06780697405338287, Validation Loss = 0.06808434426784515\n",
      "Epoch 8, Iteration 0: Training Loss = 0.06817218661308289, Validation Loss = 0.06637675315141678\n",
      "Epoch 00009: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 9, Iteration 0: Training Loss = 0.0634155198931694, Validation Loss = 0.06786283105611801\n"
     ]
    }
   ],
   "source": [
    "# combining a transformer with a cellular automata: dna sim\n",
    "from dna_ca import DNA_CA\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 128\n",
    "max_iter = 2500\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 64\n",
    "n_head = 8\n",
    "n_layer = 16\n",
    "dropout = 0.1\n",
    "grid_width = 3\n",
    "text = []\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['A', 'T', 'C', 'G', '0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])\n",
    "\n",
    "#  train and test splits \n",
    "def generate_random_input_string(size):\n",
    "    \"\"\"Generate a random grid as a string for a given grid size.\"\"\"\n",
    "    game1 = DNA_CA(size, grid_width, step_count)\n",
    "    x = (game1.initialize_grid_with_modifiers())\n",
    "    return (game1.flatten_grid(x))\n",
    "\n",
    "def generate_ATCG_sequence(batch_size, grid_size, step_count):\n",
    "    initial_states = [generate_random_input_string(grid_size) for _ in range(batch_size)]\n",
    "    final_states = []\n",
    "    for state in initial_states:\n",
    "        game = DNA_CA(grid_size, grid_width, step_count)\n",
    "        final_state_array = game.run_simulation()\n",
    "        # final_state_str = ''.join(final_state_array.flatten())\n",
    "        final_states.append(final_state_array)\n",
    "    return initial_states, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size\n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_ATCG_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            # loss = F.cross_entropy(logits, targets)\n",
    "            loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_atcg_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: G10A10A01A01A10G10G00C11A10G10G10A01A11C00T00T00G10T01G10A01C11T00C01G00T11G00C11T11G01C10T11A11T00C10A01A00G10G10T10A10T10T00A11A10G00C00A00A10A11T00C11T01G01G11G11T01A11C10C00A01C11A00T10T01\n",
      "Generated from T is: G10A10A01A01A10G10G00C11A10G10G10A01A11C00T00T00G10T01G10A01C11T00C01G00T11G00C11T11G01C10T11A11T00C10A01A00G10G10T10A10T10T00A11A10G00C00A00A10A11T00C11T01G01G11G11T01A11C10C00A01C11A00T10T01e1AT1TT1AeesGG00CAGT0s1TTC0sCAGseGT1TTTGCTGA010eTCC10A000eGe1sA0ssGCGesTCGCT1eeTTGe01GGsTsC1T1TeCC01CT11C1GAeAATC1C1sAG00AAA10eCAGGA11CeA11Te1AGTee1GCsGeeCs01Cs10G0TTCACTGCC0TeCT10AsCssAC0CTe0\n",
      "Generated from CA is: G00G01T01G01G10G11G00C01G10G01A01C11G00G01G10C11G10A11G10C11G10C11G10C11\n",
      "\n",
      "Generated from CA finally is: G00G01T01G01G10G11G00C01G10G01A01C11G00G01G10C11G10A11G10C11G10C11G10C11\n",
      "\n",
      "\n",
      "Generated from T modified is: 1AT1TT1AeesGG00CAGT0s1TTC0sCAGseGT1TTTGCTGA010eTCC10A000eGe1sA0ssGCGesTCGCT1eeTTGe01GGsTsC1T1TeCC01CT11C1GAeAATC1C1sAG00AAA10eCAGGA11CeA11Te1AGTee1GCsGeeCs01Cs10G0TTCACTGCC0TeCT10AsCssAC0CTe0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_atcg_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "generations = 2\n",
    "grid_length = input_length\n",
    "grid_width = 3 # Keep it square - no idea why it has to be\n",
    "game1 = DNA_CA(input_length, input_length, step_count)\n",
    "x = (game1.initialize_grid_with_modifiers())\n",
    "input_sequence = (game1.flatten_grid(x))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = DNA_CA(grid_length, grid_width, generations=generations)\n",
    "print(f\"Generated from T is: {generated_text_t}\")\n",
    "\n",
    "if generated_text_t.startswith('s'):\n",
    "    generated_text_t = generated_text_t[1:]\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "_, model_generated_sequence = generated_text_t.split('e', 1)\n",
    "\n",
    "print(f\"Generated from CA is: {generated_text_ca}\")\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'A': 'red', 'T': 'blue', 'C': 'green', 'G': 'yellow', '0': 'grey', '1': 'white', ' ': 'black'}\n",
    "    colors = []\n",
    "    \n",
    "    if isinstance(grid, np.ndarray):  # Handling NumPy arrays from CA generations\n",
    "        grid = grid.astype(str)  # Ensure the array elements are strings for color mapping\n",
    "        for generation in grid:\n",
    "            for cell in generation.flat:\n",
    "                colors.append(base_colors[cell])\n",
    "    elif isinstance(grid, str):  # Handling model generated sequences as strings\n",
    "        for base in grid:\n",
    "            colors.append(base_colors.get(base, 'black'))  # Default to black for unexpected characters\n",
    "    \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA finally is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T modified is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output\n",
    "\n",
    "# ca = game.unflatten_string(generated_text_ca)\n",
    "# t = game.unflatten_string(model_generated_sequence)\n",
    "# game.visualize_grid_with_modifiers(ca)\n",
    "# game.visualize_grid_with_modifiers(t)  # Use the fixed, split decoded output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
