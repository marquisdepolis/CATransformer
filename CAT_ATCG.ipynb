{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 0.15503224730491638, Validation Loss = 0.163933664560318\n"
     ]
    }
   ],
   "source": [
    "# combining a transformer with a cellular automata: dna sim\n",
    "from dna_ca import DNA_CA\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 128\n",
    "max_iter = 5000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 64\n",
    "n_head = 16\n",
    "n_layer = 32\n",
    "dropout = 0.2\n",
    "grid_width = 3\n",
    "text = []\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['A', 'T', 'C', 'G', '0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])\n",
    "\n",
    "#  train and test splits \n",
    "def generate_ATCG_sequence(batch_size, grid_size, step_count):\n",
    "    final_states = []\n",
    "    initial_states = []\n",
    "    for _ in range(batch_size):\n",
    "        game = DNA_CA(grid_size, grid_width, step_count)\n",
    "        initial_state_array = game.initialize_grid_with_modifiers()\n",
    "        initial_state_str = game.flatten_grid(initial_state_array)\n",
    "        final_state_array = game.generate_output_with_modifiers(initial_state_array)\n",
    "        initial_states.append(initial_state_str)        \n",
    "        final_state_str = game.flatten_grid(final_state_array)\n",
    "        final_states.append(final_state_str)\n",
    "    return initial_states, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size\n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_ATCG_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            # loss = F.cross_entropy(logits, targets)\n",
    "            loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_atcg_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: C11G11A11G01G00A10T10A11G01G01T01A01T01A00C11G11A00G11G00C10A11G00T10C00C00T10T10A01T01C10G00T11C00G10T01G00G01A01T10A00C10C00G11C01A00G10C11A10A01C00C10A00C11G10C01G01G11A00C00T01C10T00G10T00\n",
      "Generated from T is: C11G11A11G01G00A10T10A11G01G01T01A01T01A00C11G11A00G11G00C10A11G00T10C00C00T10T10A01T01C10G00T11C00G10T01G00G01A01T10A00C10C00G11C01A00G10C11A10A01C00C10A00C11G10C01G01G11A00C00T01C10T00G10T00e01GAGssAsAGe1CssTsGseesT1ATA0AAAG0Gee1C1eGTGAGseCGTAAsACAA1GAT0CCG10GsAeGG1CGCe10C0G1G001sCs1s1sTGGTGsTse00CssGeCeGG0TeeCsGs010TC0eAAGGAGTsA0T1TA01esTsssG0AsCGCsse0s1TeTA0T0eeT101A1AA1e00s1eC\n",
      "\n",
      "Generated from CA finally is: T00T01G00G01G00T01G00G01G00G00G00G01G10G00G00G10G00A01A10G10G10A11G10G10\n",
      "\n",
      "\n",
      "Generated from T modified is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_atcg_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "generations = 2\n",
    "grid_length = input_length\n",
    "grid_width = 3\n",
    "game1 = DNA_CA(input_length, input_length, step_count)\n",
    "x = (game1.initialize_grid_with_modifiers())\n",
    "input_sequence = (game1.flatten_grid(x))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = DNA_CA(grid_length, grid_width, generations=generations)\n",
    "print(f\"Generated from T is: {generated_text_t}\")\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "\n",
    "_, model_generated_sequence = generated_text_t[len(input_sequence)].split('e', 1)\n",
    "# if model_generated_sequence.startswith('s'):\n",
    "#     model_generated_sequence = model_generated_sequence[1:]\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'A': 'red', 'T': 'blue', 'C': 'green', 'G': 'yellow', '0': 'grey', '1': 'white'}\n",
    "    colors = []\n",
    "    \n",
    "    if isinstance(grid, np.ndarray):  # Handling NumPy arrays from CA generations\n",
    "        grid = grid.astype(str)  # Ensure the array elements are strings for color mapping\n",
    "        for generation in grid:\n",
    "            for cell in generation.flat:\n",
    "                colors.append(base_colors[cell])\n",
    "    elif isinstance(grid, str):  # Handling model generated sequences as strings\n",
    "        for base in grid:\n",
    "            colors.append(base_colors.get(base, 'black'))  # Default to black for unexpected characters\n",
    "    \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA finally is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T modified is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
