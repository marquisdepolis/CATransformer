{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 1.5233509540557861, Validation Loss = 1.2075026035308838\n",
      "Epoch 1, Iteration 0: Training Loss = 0.7409172654151917, Validation Loss = 0.7376871705055237\n",
      "Epoch 2, Iteration 0: Training Loss = 0.7051730155944824, Validation Loss = 0.7057102918624878\n",
      "Epoch 3, Iteration 0: Training Loss = 0.6959173679351807, Validation Loss = 0.6990970969200134\n",
      "Epoch 4, Iteration 0: Training Loss = 0.6909492611885071, Validation Loss = 0.6913312077522278\n",
      "Epoch 5, Iteration 0: Training Loss = 0.6898287534713745, Validation Loss = 0.6928672194480896\n",
      "Epoch 6, Iteration 0: Training Loss = 0.686291515827179, Validation Loss = 0.6891059279441833\n",
      "Epoch 7, Iteration 0: Training Loss = 0.688783586025238, Validation Loss = 0.689996600151062\n",
      "Epoch 8, Iteration 0: Training Loss = 0.685198187828064, Validation Loss = 0.688252329826355\n",
      "Epoch 9, Iteration 0: Training Loss = 0.6897444128990173, Validation Loss = 0.6882750391960144\n"
     ]
    }
   ],
   "source": [
    "# transformer plus cellular automata: conway game of life\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "from gameoflife import GameOfLife\n",
    "\n",
    "batch_size = 8\n",
    "block_size = 256 # Has to be the square of grid_size to read the full grid\n",
    "max_iter = 2000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 5e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 64\n",
    "n_head = 8\n",
    "n_layer = 8\n",
    "dropout = 0.2\n",
    "text = []\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 10  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])  # Skipping the first and last items ('s' and 'e')\n",
    "\n",
    "def generate_random_input_string(size):\n",
    "    \"\"\"Generate a random grid as a string for a given grid size.\"\"\"\n",
    "    return ''.join(np.random.choice(tokens[:2], size*size))\n",
    "\n",
    "def generate_game_of_life_sequence(batch_size, grid_size, step_count):\n",
    "    \"\"\"Generate a batch of Game of Life initial states and final states.\"\"\"\n",
    "    initial_states = [generate_random_input_string(grid_size) for _ in range(batch_size)]\n",
    "    final_states = []\n",
    "    for state in initial_states:\n",
    "        # Directly use state without 's' and 'e' tokens for simulation\n",
    "        game = GameOfLife(input_string=state, generations=step_count)\n",
    "        final_state = game.run_simulation()  # Assuming this returns the final state string\n",
    "        # Only add 's' and 'e' tokens for neural network processing, not for GameOfLife simulation\n",
    "        final_state_with_tokens = 's' + final_state + 'e'\n",
    "        final_states.append(final_state_with_tokens)\n",
    "    # Add 's' and 'e' tokens to initial states after simulation to maintain consistency\n",
    "    initial_states_with_tokens = ['s' + state + 'e' for state in initial_states]\n",
    "    return initial_states_with_tokens, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = 20  \n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_game_of_life_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "# bigram language model\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            # loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_cgol_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: 1000111000000010001010100000000000010011100100010111110111111010\n",
      "\n",
      "Generated from CA is: 0001110110000000001111110101100111011001010100000101101111000011\n",
      "\n",
      "\n",
      "Generated from T is: 011011100010101101011110100000000010100100010111010000101001011\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_cgol_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "input_sequence = ''.join(np.random.choice(tokens[:2], input_length*input_length))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = GameOfLife(input_sequence, generations=10)\n",
    "\n",
    "if generated_text_t.startswith('s'):\n",
    "    generated_text_t = generated_text_t[1:]\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "_, model_generated_sequence = generated_text_t.split('e', 1)\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'0': 'red', '1': 'blue', ' ': 'grey'}\n",
    "    colors = []\n",
    "    for row in grid:\n",
    "        row_colors = [base_colors[base] for base in row]\n",
    "        colors.extend(row_colors)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
