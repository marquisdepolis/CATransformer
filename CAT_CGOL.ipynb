{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 1.353273868560791, Validation Loss = 0.8169969320297241\n",
      "Epoch 1, Iteration 0: Training Loss = 0.6541997194290161, Validation Loss = 0.6601845026016235\n",
      "Epoch 2, Iteration 0: Training Loss = 0.6531018614768982, Validation Loss = 0.6503849625587463\n",
      "Epoch 3, Iteration 0: Training Loss = 0.6524629592895508, Validation Loss = 0.6484466791152954\n",
      "Epoch 4, Iteration 0: Training Loss = 0.6423239707946777, Validation Loss = 0.6487427949905396\n",
      "Epoch 5, Iteration 0: Training Loss = 0.6458955407142639, Validation Loss = 0.6476337313652039\n",
      "Epoch 6, Iteration 0: Training Loss = 0.6503651738166809, Validation Loss = 0.645435631275177\n",
      "Epoch 7, Iteration 0: Training Loss = 0.6345137357711792, Validation Loss = 0.6496675610542297\n",
      "Epoch 8, Iteration 0: Training Loss = 0.6603278517723083, Validation Loss = 0.6469020247459412\n",
      "Epoch 9, Iteration 0: Training Loss = 0.660546600818634, Validation Loss = 0.6451559066772461\n"
     ]
    }
   ],
   "source": [
    "# transformer plus cellular automata: conway game of life\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "from gameoflife import GameOfLife\n",
    "\n",
    "batch_size = 8\n",
    "block_size = 256 # Has to be the square of grid_size to read the full grid\n",
    "max_iter = 2000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 128\n",
    "n_head = 8\n",
    "n_layer = 16\n",
    "dropout = 0.2\n",
    "text = []\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['0', '1', 's', 'e']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 16  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi['s']] + [stoi[c] for c in s] + [stoi['e']]\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])\n",
    "\n",
    "def generate_random_input_string(size):\n",
    "    \"\"\"Generate a random grid as a string for a given grid size.\"\"\"\n",
    "    return ''.join(np.random.choice(tokens[:2], size*size))\n",
    "\n",
    "def generate_game_of_life_sequence(batch_size, grid_size, step_count):\n",
    "    \"\"\"Generate a batch of Game of Life initial states and final states.\"\"\"\n",
    "    initial_states = [generate_random_input_string(grid_size) for _ in range(batch_size)]\n",
    "    final_states = []\n",
    "    for state in initial_states:\n",
    "        # Directly use state without 's' and 'e' tokens for simulation\n",
    "        game = GameOfLife(input_string=state, generations=step_count)\n",
    "        final_state = game.run_simulation()  # Assuming this returns the final state string\n",
    "        # Only add 's' and 'e' tokens for neural network processing, not for GameOfLife simulation\n",
    "        final_state_with_tokens = 's' + final_state + 'e'\n",
    "        final_states.append(final_state_with_tokens)\n",
    "    # Add 's' and 'e' tokens to initial states after simulation to maintain consistency\n",
    "    initial_states_with_tokens = ['s' + state + 'e' for state in initial_states]\n",
    "    return initial_states_with_tokens, final_states\n",
    "\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = 20  \n",
    "\n",
    "# load data\n",
    "def get_batch(batch_size, grid_size, step_count, block_size):\n",
    "    initial_states, final_states = generate_game_of_life_sequence(batch_size, grid_size, step_count)\n",
    "    X = torch.tensor([enc(s)[:block_size] for s in initial_states], dtype=torch.long)\n",
    "    Y = torch.tensor([enc(s)[:block_size] for s in final_states], dtype=torch.long)\n",
    "    return X.to(device), Y.to(device)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "# bigram language model\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            # loss = F.mse_loss(logits, F.one_hot(targets, num_classes=vocab_size).float())\n",
    "\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, grid_size, step_count, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, grid_size, step_count, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "# Save:\n",
    "torch.save(model, 'cat_cgol_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: 1010101101010110111110001011001110011010001111100111111010000000\n",
      "\n",
      "Generated from CA is: 1101101111100011010011001100101011100110101001101101111000001101\n",
      "\n",
      "\n",
      "Generated from T is: 111111111110000100011111111100110011110011111011011000000001110\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = torch.load('cat_cgol_model.pth')\n",
    "model.eval()\n",
    "input_length = 8\n",
    "generations = 2\n",
    "input_sequence = ''.join(np.random.choice(tokens[:2], input_length*input_length))\n",
    "print(f\"Input is: {input_sequence}\")\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "game = GameOfLife(input_sequence, generations=generations)\n",
    "\n",
    "if generated_text_t.startswith('s'):\n",
    "    generated_text_t = generated_text_t[1:]\n",
    "\n",
    "generated_text_ca = game.run_simulation()\n",
    "_, model_generated_sequence = generated_text_t.split('e', 1)\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'0': 'red', '1': 'blue', ' ': 'grey'}\n",
    "    colors = []\n",
    "    for row in grid:\n",
    "        row_colors = [base_colors[base] for base in row]\n",
    "        colors.extend(row_colors)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T is: {model_generated_sequence}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(model_generated_sequence)  # Use the fixed, split decoded output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
