{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer plus a simple equations: learning some wave rules\n",
    "import torch\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "from wavefn import WaveFunction\n",
    "\n",
    "batch_size = 8\n",
    "block_size = 64\n",
    "max_iter = 10000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 4e-5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_embed = 64\n",
    "n_head = 16\n",
    "n_layer = 16\n",
    "dropout = 0.1\n",
    "text = []\n",
    "\n",
    "# tokens set as integers\n",
    "tokens = ['F1', 'F2', 'F3', 'F4', '_', 'M', 'H', 'B','s','e']\n",
    "\n",
    "# Let's make some waves! Not strictly needed, but repurposing the wave fn so keeping it for now\n",
    "c = 1.0  # Wave speed\n",
    "dx = 0.1  # Spatial step size\n",
    "dt = 0.1  # Time step size\n",
    "wave_fn = WaveFunction(c, dx, dt)\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "def enc(s, pad_length):\n",
    "    encoded = [stoi[ch] for ch in s if ch in stoi]\n",
    "    padding = [stoi['_']] * (pad_length - len(encoded))  # Padding token is '_'\n",
    "    return encoded + padding[:max(0, pad_length - len(encoded))]  # Ensures the sequence is exactly pad_length long\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])  # Skipping the first and last items ('s' and 'e')\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size  \n",
    "\n",
    "def generate_operation_sequence_with_objective(block_size):\n",
    "    objective = random.choice(['M', 'H', 'B'])\n",
    "    if objective == 'M':\n",
    "        sequence = ['F1', 'F4', 'e', '_', '_', '_', '_']\n",
    "    elif objective == 'H':\n",
    "        sequence = ['F2', 'F3', 'e', '_', '_', '_', '_']\n",
    "    else:  # B includes all operations\n",
    "        sequence = ['F1', 'F2', 'F3', 'F4', 'e', '_', '_']\n",
    "\n",
    "    # Ensure the sequence length does not exceed block size - 2 for start/end tokens\n",
    "    sequence = sequence[:block_size - 2]\n",
    "    return [objective] + sequence\n",
    "\n",
    "def apply_operations_sequence_to_wave(sequence, initial_wave):\n",
    "    wave_fn = WaveFunction()\n",
    "    current_profile = np.array(initial_wave, dtype=int)\n",
    "    operations_map = {\n",
    "        'F1': wave_fn.F1, 'F2': wave_fn.F2, 'F3': wave_fn.F3, 'F4': wave_fn.F4,\n",
    "        '_': lambda x: x  # No-operation function returns the input as is\n",
    "    }\n",
    "    \n",
    "    # Start applying transformations after the objective; skip '_'\n",
    "    for op in sequence[1:]:  # Skip the 'objective' token\n",
    "        if op in operations_map:  # Check if operation is defined in the map\n",
    "            current_profile = operations_map[op](current_profile)\n",
    "    \n",
    "    return current_profile\n",
    "\n",
    "def get_batch(batch_size, block_size):\n",
    "    sequences = [generate_operation_sequence_with_objective(block_size) for _ in range(batch_size)]\n",
    "    X, Y = [], []\n",
    "    for seq in sequences:\n",
    "        x_encoded = [stoi[ch] for ch in seq]  # All tokens in seq are input\n",
    "        # Correct target padding to ensure each target matches logits\n",
    "        y_encoded = [stoi[ch] for ch in seq[1:]] + [stoi['_']] * (8 - len(seq[1:]))  # Pad to T=8, not block_size\n",
    "        X.append(torch.tensor(x_encoded, dtype=torch.long).to(device))\n",
    "        Y.append(torch.tensor(y_encoded, dtype=torch.long).to(device))\n",
    "    X = torch.stack(X)  # Stack all sequences\n",
    "    Y = torch.stack(Y)  # Stack targets (important change from cat to stack)\n",
    "    return X, Y.view(-1)  # Flatten Y to match logits\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class SinusoidalActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(x)\n",
    "        return x + torch.sin(x) ** 2\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.GELU(),\n",
    "            # SinusoidalActivation(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        attn_output = self.sa(self.ln1(x))\n",
    "        x = x + attn_output  # add & norm for attention\n",
    "        ffwd_output = self.ffwd(self.ln2(x))\n",
    "        x = x + ffwd_output  # add & norm for feedforward\n",
    "        return x\n",
    "\n",
    "# bigram language model\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size  # Save block_size as an instance variable\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape  # Confirm dimensions: B should be 8, T should be 8\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)).unsqueeze(0).expand(B, T, -1)\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        logits = logits.view(-1, self.vocab_size)  # Flatten logits\n",
    "\n",
    "        if targets is not None:\n",
    "            # print(f'Logits final shape for cross-entropy: {logits.shape}')  # Should be [64, 8]\n",
    "            # print(f'Targets shape for cross-entropy: {targets.shape}')  # Should also be [64]\n",
    "            if logits.shape[0] != targets.shape[0]:\n",
    "                raise ValueError(f\"Logits and targets count mismatch: {logits.shape[0]} vs {targets.shape[0]}\")\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        outputs = idx\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = outputs[:, -block_size:] if outputs.size(1) > block_size else outputs\n",
    "            logits, _ = self(idx_cond)\n",
    "            if logits.dim() == 2:\n",
    "                logits = logits.unsqueeze(1)  # Ensure we have [batch, sequence, features]\n",
    "            logits = logits[:, -1, :]  # Get the last token's logits for next prediction\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).squeeze(-1)  # Simplify to [batch, sequence]\n",
    "\n",
    "            # Debug shapes to ensure correct dimensions\n",
    "            # print(f'outputs shape: {outputs.shape}')\n",
    "            # print(f'idx_next shape: {idx_next.shape}')\n",
    "\n",
    "            # Ensure idx_next matches outputs' batch size\n",
    "            if idx_next.dim() == 1:\n",
    "                idx_next = idx_next.unsqueeze(0)  # Correct shape to [1, 1]\n",
    "\n",
    "            outputs = torch.cat([outputs, idx_next], dim=1)  # Concatenate along sequence dimension\n",
    "        return outputs\n",
    "\n",
    "def apply_predicted_operations(predicted_operations, initial_wave):\n",
    "    wave_fn = WaveFunction()\n",
    "    current_profile = np.array(initial_wave, dtype=int)\n",
    "    operations_map = {'F1': wave_fn.F1, 'F2': wave_fn.F2, 'F3': wave_fn.F3, 'F4': wave_fn.F4}\n",
    "    \n",
    "    for op in predicted_operations:\n",
    "        if op in operations_map:\n",
    "            current_profile = operations_map[op](current_profile)\n",
    "    \n",
    "    return current_profile\n",
    "\n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=0.01, momentum=0.5, centered=False)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.9, eps=1e-06, weight_decay=0.01)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        max_norm = 1\n",
    "        # Clip gradients to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "torch.save(model, 'models/cat_wavefn_model_orig.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from wavefn import WaveFunction\n",
    "\n",
    "# Setting up the environment\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the pre-trained model and set it to evaluation mode\n",
    "model = torch.load('models/cat_wavefn_model_orig.pth', map_location=device)\n",
    "model.eval()\n",
    "# np.random.seed(42)  # Seed for reproducibility\n",
    "# Initialize the WaveFunction class\n",
    "wave_fn = WaveFunction()\n",
    "# Generate a random initial wave profile\n",
    "input_length = 32\n",
    "initial_wave = (np.random.rand(input_length) * 10).astype(int)\n",
    "print(f\"Initial Wave Profile: {initial_wave}\")\n",
    "\n",
    "# Prepare the model input\n",
    "initial_conditions = ['H']\n",
    "input_tensor = torch.tensor([[stoi[ch] for ch in initial_conditions]], dtype=torch.long).to(device)\n",
    "\n",
    "# Predict operations\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tensor, max_new_tokens=3)\n",
    "    transformer_output = dec(output[0].tolist())\n",
    "\n",
    "print(f\"Transformer output is: {transformer_output}\")\n",
    "def parse_operations(input_string):\n",
    "    match = re.match(r'(F\\d)+', input_string)\n",
    "    if match:\n",
    "        # Extract all 'F' followed by a digit from the matched group\n",
    "        return re.findall(r'F\\d', match.group())\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "predicted_operations = parse_operations(transformer_output)\n",
    "\n",
    "# Compare with direct simulation from WaveFunction using an objective\n",
    "objective_wave_output = wave_fn.simulate_wave_equation(initial_wave, objective=initial_conditions[0])\n",
    "print(f\"Objective wave output is: {objective_wave_output}\")\n",
    "print(f\"Predicted operations are: {predicted_operations}\")\n",
    "transformed_wave = wave_fn.custom_transform(initial_wave, predicted_operations)\n",
    "print(f\"Transformed wave is: {transformed_wave}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(initial_wave, label='Initial Wave', marker='o')\n",
    "plt.title('Initial Wave')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(objective_wave_output, label='Objective-Based Transformation', marker='x')\n",
    "plt.title('Objective-Based Transformation')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(transformed_wave, label='Transformer Predicted Transformation', marker='x')\n",
    "plt.title('Transformer Predicted Transformation')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
