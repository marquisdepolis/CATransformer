{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000\n",
      "step 0: train loss 1.3915,val loss 1.388822\n",
      "step 50: train loss 1.3878,val loss 1.388502\n",
      "step 100: train loss 1.3879,val loss 1.387109\n",
      "step 150: train loss 1.3920,val loss 1.389737\n",
      "step 200: train loss 1.3884,val loss 1.388030\n",
      "step 250: train loss 1.3878,val loss 1.387489\n",
      "step 300: train loss 1.3879,val loss 1.387523\n",
      "step 350: train loss 1.3877,val loss 1.386928\n",
      "step 400: train loss 1.3873,val loss 1.386714\n",
      "step 450: train loss 1.3866,val loss 1.387355\n",
      "step 500: train loss 1.3874,val loss 1.387710\n",
      "step 550: train loss 1.3862,val loss 1.387200\n",
      "step 600: train loss 1.3873,val loss 1.387906\n",
      "step 650: train loss 1.3865,val loss 1.387132\n",
      "step 700: train loss 1.3863,val loss 1.386712\n",
      "step 750: train loss 1.3866,val loss 1.386715\n",
      "step 800: train loss 1.3866,val loss 1.386782\n",
      "step 850: train loss 1.3864,val loss 1.386773\n",
      "step 900: train loss 1.3868,val loss 1.386871\n",
      "step 950: train loss 1.3868,val loss 1.386789\n",
      "AAGATCCCTACCGTCCCGGCCAACGCCATACGGAGCCTATAGGTATAAAGGAACCGCTGATCGTACTACACTGCGATAAATTGGACAGACTGTCGCCCCACAAACAAATACCACTAGCATCACGTGCTGCAAGACTTAGAGCTCTGTTTGTTTTCTGCCACATGACCTTAGTGTATCTCGAGCCTAACGGTTTCTGAGTTAACGCACAATGTTATGAGAGCATAGGACTCTAACTAGAACCCATCTTGGTTATCCCGAGTAAGCTGCACAGTTAACCTTAACAACCGTCAGCAACCTACACCCGGGTCCATGTTAGAATTCTTCAACATATGTACATCTAGTTGGGTGCTTTCCTGTTCAAACAGCTAATGGCGTTTCCGAATTAAGTGAGTATTTTTGACGGGAACGGACAAGCGCCCCGGTACGTTTTCGTGAAATCTACCTGTCAGACAATCAGTAATCGCTAGCCATCTATCTAGTAGATGATTAGCATCGTTGAGG\n"
     ]
    }
   ],
   "source": [
    "# transformer plus cellular automata: precomputed\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "\n",
    "batch_size = 2\n",
    "block_size = 32\n",
    "max_iter = 1000\n",
    "eval_interval = 50\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 100\n",
    "n_embed = 32\n",
    "n_head = 2\n",
    "n_layer = 2\n",
    "dropout = 0.01\n",
    "\n",
    "torch.manual_seed(100)\n",
    "\n",
    "def cellular_automata(grid_size, step_count, rule):\n",
    "    \"\"\"Generates a grid based on cellular automata rules.\"\"\"\n",
    "    grid = np.random.randint(5, size=(grid_size, grid_size))\n",
    "    for _ in range(step_count):\n",
    "        new_grid = np.zeros_like(grid)\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                # Define neighborhood\n",
    "                neighborhood = grid[(i-1):(i+2), (j-1):(j+2)].flatten()\n",
    "                # Apply rule to determine next state\n",
    "                new_grid[i, j] = rule(neighborhood)\n",
    "        grid = new_grid\n",
    "    return grid\n",
    "\n",
    "def example_rule(neighborhood):\n",
    "    result = np.sum(neighborhood)\n",
    "    # prod = np.prod(neighborhood) % 4\n",
    "    result = (result) % 4\n",
    "    return result\n",
    "\n",
    "# Encodes cellular automata grid to sequence of tokens\n",
    "def grid_to_sequence(grid):\n",
    "    flat_grid = grid.flatten()\n",
    "    sequence = ''.join(tokens[i % len(tokens)] for i in flat_grid)\n",
    "    return sequence\n",
    "\n",
    "# create dictionaries and then define unique characters for encoding and decoding\n",
    "tokens = ['A', 'T', 'C', 'G']\n",
    "\n",
    "# Example usage with cellular automata\n",
    "grid_size = 1000  # Grid size for the cellular automata\n",
    "step_count = 2  # Number of steps to evolve the cellular automata\n",
    "automata_grid = cellular_automata(grid_size, step_count, example_rule)\n",
    "text = grid_to_sequence(automata_grid)\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "enc = lambda s: [stoi[c] for c in s]\n",
    "dec = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "#  train and test splits\n",
    "data = torch.tensor(enc(text), dtype = torch.long)\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(len(train_data))\n",
    "\n",
    "# train_data test visualisation\n",
    "# offset = 1\n",
    "# x = train_data[offset+1:block_size+offset]\n",
    "# y = train_data[1+offset:block_size+1+offset]\n",
    "# for t in range(block_size):\n",
    "#     context = x[:t+1]\n",
    "#     target = y[t]\n",
    "#     print(f\"when input is {context} then target is: {target}\")\n",
    "\n",
    "# load data %%\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    if len(data) <= block_size:\n",
    "        raise ValueError(f\"Data length {len(data)} is too small for block size {block_size}\")\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X,Y)\n",
    "            losses[k]= loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return(out)\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x + self.sa(self.ln1(x)) # add x for residual connections\n",
    "        x = x + self.ffwd(self.ln1(x))\n",
    "        return x\n",
    "\n",
    "# bigram language model\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.token_embedding_table(idx)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
    "        x = tok_emb+pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        # print(f\"logits are shape {logits.shape} are: {logits} for idx: {idx}\")\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(-1, vocab_size)  # Reshape logits to [batch_size * block_size, vocab_size]\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * block_size]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            # print(f\"logits are shape {logits.shape} are: {loss} for idx: {idx}\")\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,num_samples=1)\n",
    "            idx=torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx\n",
    "    \n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iter):\n",
    "    if iter % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f},val loss {losses['val']:4f}\")\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "context = torch.zeros((1,1), dtype = torch.long, device = device)\n",
    "print(dec(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated from CA is: AAAAAGCCAGTAATAT\n",
      "\n",
      "\n",
      "Generated from T is: TAGAGGCAATGCGATC\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a sequence\n",
    "input_sequence = \"ATCG\"\n",
    "context = torch.tensor(enc(input_sequence), dtype=torch.long, device=device).unsqueeze(0)\n",
    "output = model.generate(context, max_new_tokens=4*len(input_sequence))\n",
    "generated_text_t = dec(output[0].tolist())\n",
    "generated_text_ca = grid_to_sequence(cellular_automata(len(input_sequence), step_count, example_rule))\n",
    "\n",
    "def visualize_grid_with_modifiers(grid):\n",
    "    \"\"\"Visualise the grid.\"\"\"\n",
    "    base_colors = {'A': 'red', 'T': 'blue', 'C': 'green', 'G': 'yellow'}\n",
    "    colors = []\n",
    "    for row in grid:\n",
    "        row_colors = [base_colors[base] for base in row]\n",
    "        colors.extend(row_colors)\n",
    "\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.bar(range(len(colors)), np.ones(len(colors)), color=colors)\n",
    "    plt.axis('off')\n",
    "    plt.title('Visualization with Modifiers')\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nGenerated from CA is: {generated_text_ca}\\n\")\n",
    "print(f\"\\nGenerated from T is: {generated_text_t[4:]}\\n\")\n",
    "visualize_grid_with_modifiers(generated_text_ca)\n",
    "visualize_grid_with_modifiers(generated_text_t[4:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
