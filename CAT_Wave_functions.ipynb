{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0: Training Loss = 2.08620285987854, Validation Loss = 1.720586895942688\n",
      "Epoch 1, Iteration 0: Training Loss = 0.06775912642478943, Validation Loss = 0.06311294436454773\n",
      "Epoch 2, Iteration 0: Training Loss = 0.018831947818398476, Validation Loss = 0.01729976199567318\n",
      "Epoch 3, Iteration 0: Training Loss = 0.008490938693284988, Validation Loss = 0.00882628932595253\n",
      "Epoch 4, Iteration 0: Training Loss = 0.005634819623082876, Validation Loss = 0.005472458899021149\n",
      "Epoch 5, Iteration 0: Training Loss = 0.003730582073330879, Validation Loss = 0.0032127031590789557\n",
      "Epoch 6, Iteration 0: Training Loss = 0.002684080507606268, Validation Loss = 0.0025460761971771717\n"
     ]
    }
   ],
   "source": [
    "# transformer plus a simple equations: learning some wave rules\n",
    "import torch\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "from wavefn import WaveFunction\n",
    "\n",
    "batch_size = 8\n",
    "block_size = 32\n",
    "max_iter = 1000\n",
    "epochs = 10\n",
    "eval_interval = 500\n",
    "learning_rate = 5e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n_embed = 64\n",
    "n_head = 16\n",
    "n_layer = 16\n",
    "dropout = 0.05\n",
    "text = []\n",
    "\n",
    "# tokens set as integers\n",
    "tokens = ['F1', 'F2', 'F3', 'F4', '_', 'M', 'H', 'B']\n",
    "\n",
    "# Let's make some waves! Not strictly needed, but repurposing the wave fn so keeping it for now\n",
    "c = 1.0  # Wave speed\n",
    "dx = 0.1  # Spatial step size\n",
    "dt = 0.1  # Time step size\n",
    "wave_fn = WaveFunction(c, dx, dt)\n",
    "\n",
    "vocab_size=len(tokens)\n",
    "stoi = { ch:i for i, ch in enumerate(tokens)}\n",
    "itos = { i:ch for i, ch in enumerate(tokens)}\n",
    "def enc(s, pad_length):\n",
    "    encoded = [stoi[ch] for ch in s if ch in stoi]\n",
    "    padding = [stoi['_']] * (pad_length - len(encoded))  # Padding token is '_'\n",
    "    return encoded + padding[:max(0, pad_length - len(encoded))]  # Ensures the sequence is exactly pad_length long\n",
    "dec = lambda l: ''.join([itos[i] for i in l[1:-1]])  # Skipping the first and last items ('s' and 'e')\n",
    "# Define an appropriate size for your validation batch\n",
    "val_batch_size = batch_size  \n",
    "\n",
    "def generate_operation_sequence_with_objective(block_size):\n",
    "    objective = random.choice(['M', 'H', 'B'])\n",
    "    if objective == 'M':\n",
    "        sequence = ['F1', '_', '_', 'F4']\n",
    "    elif objective == 'H':\n",
    "        sequence = ['_', 'F2', 'F3', '_']\n",
    "    else:  # B includes all operations\n",
    "        sequence = ['F1', 'F2', 'F3', 'F4']\n",
    "\n",
    "    # Ensure the sequence length does not exceed block size - 2 for start/end tokens\n",
    "    sequence = sequence[:block_size - 2]\n",
    "    return [objective] + sequence\n",
    "\n",
    "def apply_operations_sequence_to_wave(sequence, initial_wave):\n",
    "    wave_fn = WaveFunction()\n",
    "    current_profile = np.array(initial_wave, dtype=int)\n",
    "    operations_map = {\n",
    "        'F1': wave_fn.F1, 'F2': wave_fn.F2, 'F3': wave_fn.F3, 'F4': wave_fn.F4,\n",
    "        '_': lambda x: x  # No-operation function returns the input as is\n",
    "    }\n",
    "    \n",
    "    # Start applying transformations after the objective; skip '_'\n",
    "    for op in sequence[1:]:  # Skip the 'objective' token\n",
    "        if op in operations_map:  # Check if operation is defined in the map\n",
    "            current_profile = operations_map[op](current_profile)\n",
    "    \n",
    "    return current_profile\n",
    "\n",
    "def get_batch(batch_size, block_size):\n",
    "    sequences = [generate_operation_sequence_with_objective(block_size) for _ in range(batch_size)]\n",
    "    X, Y = [], []\n",
    "    for seq in sequences:\n",
    "        X.append(torch.tensor([stoi[seq[0]]], dtype=torch.long).unsqueeze(0).to(device))\n",
    "        Y.append(torch.tensor([stoi[ch] for ch in seq[1:]], dtype=torch.long).to(device))\n",
    "    X = torch.cat(X, dim=0)  # [batch_size, 1]\n",
    "    Y = pad_sequence(Y, batch_first=True, padding_value=stoi['_'])  # Pad Y\n",
    "    # print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)  # Debugging statement\n",
    "    return X, Y\n",
    "\n",
    "# single head attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.query = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.value = nn.Linear(n_embed,head_size,bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) *C**-0.5 # scaled attention\n",
    "        # wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf')) # decoder block\n",
    "        wei = F.softmax(wei,dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei@v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embed,n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out =  torch.cat([h(x) for h in self.heads], dim = -1)\n",
    "        out = self.proj(out) # Projection si the linear transformation of the outcome of prev layer\n",
    "        return out\n",
    "\n",
    "class SinusoidalActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(x)\n",
    "        return x + torch.sin(x) ** 2\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed,4* n_embed), \n",
    "            nn.GELU(),\n",
    "            # SinusoidalActivation(),\n",
    "            nn.Linear(4* n_embed, n_embed),\n",
    "            nn.Dropout(dropout),\n",
    "            )\n",
    "        self\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed //n_head\n",
    "        self.sa = MultiHeadAttention(n_head,head_size)\n",
    "        self.ffwd = FeedForward(n_embed)\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        attn_output = self.sa(self.ln1(x))\n",
    "        x = x + attn_output  # add & norm for attention\n",
    "        ffwd_output = self.ffwd(self.ln2(x))\n",
    "        x = x + ffwd_output  # add & norm for feedforward\n",
    "        return x\n",
    "\n",
    "# bigram language model\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size  # Save block_size as an instance variable\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embed)\n",
    "        self.lm_head = nn.Linear(n_embed,vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape  # T should be set to the number of tokens per sequence (currently it seems to be 1)\n",
    "        idx = idx.repeat(1, 4)  # Assuming you want to handle 4 tokens per sequence\n",
    "        T = 4  # Manually setting T to 4 tokens per sequence\n",
    "\n",
    "        tok_emb = self.token_embedding_table(idx.squeeze(-1))  # [B, T, n_embed]\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)).unsqueeze(0).repeat(B, 1, 1)  # Repeat for batch\n",
    "\n",
    "        x = tok_emb + pos_emb  # Combine embeddings\n",
    "\n",
    "        x = self.blocks(x)  # Process through transformer blocks\n",
    "        x = self.ln_f(x)  # Apply final layer normalization\n",
    "        logits = self.lm_head(x)  # [B, T, vocab_size]\n",
    "        logits = logits.view(B * T, self.vocab_size)  # Reshape to [batch_size * sequence_length, vocab_size]\n",
    "\n",
    "        if targets is not None:\n",
    "            targets = targets.view(-1)  # Flatten targets to [batch_size * sequence_length]\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        outputs = idx\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = outputs[:, -block_size:] if outputs.size(1) > block_size else outputs\n",
    "            logits, loss = self(idx_cond)\n",
    "            # Check if logits is two-dimensional and adjust accordingly\n",
    "            if logits.dim() == 2:  # If only batch_size and num_classes, no sequence_length\n",
    "                logits = logits.unsqueeze(1)  # Unsqueeze to simulate sequence_length of 1\n",
    "            logits = logits[:, -1, :]  # Now this should work\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            outputs = torch.cat([outputs, idx_next], dim=1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def apply_predicted_operations(predicted_operations, initial_wave):\n",
    "    wave_fn = WaveFunction()\n",
    "    current_profile = np.array(initial_wave, dtype=int)\n",
    "    operations_map = {'F1': wave_fn.F1, 'F2': wave_fn.F2, 'F3': wave_fn.F3, 'F4': wave_fn.F4}\n",
    "    \n",
    "    for op in predicted_operations:\n",
    "        if op in operations_map:\n",
    "            current_profile = operations_map[op](current_profile)\n",
    "    \n",
    "    return current_profile\n",
    "\n",
    "model = LanguageModel()\n",
    "m = model.to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=0.01, momentum=0.5, centered=False)\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate, rho=0.9, eps=1e-06, weight_decay=0.01)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)\n",
    "loss = None  # Initialize loss variable outside the loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for iter in range(max_iter // epochs):  # Distribute iterations across epochs\n",
    "        model.train()\n",
    "        xb, yb = get_batch(batch_size, block_size)\n",
    "        logits, loss = model(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        max_norm = 1\n",
    "        # Clip gradients to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        if iter % eval_interval == 0 and loss is not None:  # Validation logic\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                xv, yv = get_batch(val_batch_size, block_size)\n",
    "                val_logits, val_loss = model(xv, yv)\n",
    "                print(f\"Epoch {epoch}, Iteration {iter}: Training Loss = {loss.item()}, Validation Loss = {val_loss.item()}\")\n",
    "            model.train()\n",
    "\n",
    "    scheduler.step(val_loss)  # Update the learning rate at the end of each epoch\n",
    "\n",
    "torch.save(model, 'models/cat_wavefn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Wave Profile: [3 9 7 5 1 1 0 8 6 7 0 9 8 2 1 1 3 5 4 2 6 1 2 3 4 7 1 5 5 0 6 1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Predict operations\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 27\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     transformer_output \u001b[38;5;241m=\u001b[39m dec(output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer output is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformer_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 200\u001b[0m, in \u001b[0;36mLanguageModel.generate\u001b[0;34m(self, idx, max_new_tokens)\u001b[0m\n\u001b[1;32m    198\u001b[0m idx_cond \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39mblock_size:]\n\u001b[1;32m    199\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(idx_cond)\n\u001b[0;32m--> 200\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    201\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    202\u001b[0m idx_next \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(probs,num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from wavefn import WaveFunction\n",
    "\n",
    "# Setting up the environment\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the pre-trained model and set it to evaluation mode\n",
    "model = torch.load('models/cat_wavefn_model.pth', map_location=device)\n",
    "model.eval()\n",
    "np.random.seed(42)  # Seed for reproducibility\n",
    "# Initialize the WaveFunction class\n",
    "wave_fn = WaveFunction()\n",
    "# Generate a random initial wave profile\n",
    "input_length = 32\n",
    "initial_wave = (np.random.rand(input_length) * 10).astype(int)\n",
    "print(f\"Initial Wave Profile: {initial_wave}\")\n",
    "\n",
    "# Prepare the model input (assuming the model takes numerical input)\n",
    "initial_conditions = ['M']\n",
    "input_tensor = torch.tensor([[stoi[ch] for ch in initial_conditions]], dtype=torch.long).to(device)\n",
    "\n",
    "# Predict operations\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tensor, max_new_tokens=5)\n",
    "    transformer_output = dec(output[0].tolist())\n",
    "\n",
    "print(f\"Transformer output is: {transformer_output}\")\n",
    "def parse_operations(input_string):\n",
    "    # Use a regular expression to find a continuous sequence of 'F' followed by a digit until another letter is encountered\n",
    "    match = re.match(r'(F\\d)+', input_string)\n",
    "    if match:\n",
    "        # Extract all 'F' followed by a digit from the matched group\n",
    "        return re.findall(r'F\\d', match.group())\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "predicted_operations = parse_operations(transformer_output)\n",
    "\n",
    "# Compare with direct simulation from WaveFunction using an objective\n",
    "objective_wave_output = wave_fn.simulate_wave_equation(initial_wave, objective='M')\n",
    "print(f\"Objective wave output is: {objective_wave_output}\")\n",
    "print(f\"Predicted operations are: {predicted_operations}\")\n",
    "transformed_wave = wave_fn.custom_transform(initial_wave, predicted_operations)\n",
    "print(f\"Transformed wave is: {transformed_wave}\")\n",
    "\n",
    "# Plotting results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(initial_wave, label='Initial Wave', marker='o')\n",
    "plt.title('Initial Wave')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(objective_wave_output, label='Objective-Based Transformation', marker='x')\n",
    "plt.title('Objective-Based Transformation')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(transformed_wave, label='Transformer Predicted Transformation', marker='x')\n",
    "plt.title('Transformer Predicted Transformation')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
